{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "file_extension": ".py",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.7"
    },
    "mimetype": "text/x-python",
    "name": "python",
    "npconvert_exporter": "python",
    "pygments_lexer": "ipython3",
    "version": 3,
    "colab": {
      "name": "Helpful_Python_snippets_for_Image_Processing_using_OpenCV.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Soedirman-Machine-Learning/experiment-repo/blob/master/Helpful_Python_snippets_for_Image_Processing_using_OpenCV.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "48nIvDQSMhpE",
        "colab_type": "text"
      },
      "source": [
        "# Helpful Python snippets for *Image Processing using OpenCV*\n",
        "\n",
        "# Table Of Contents\n",
        "1. [I/0: Read,Show,Write Images](#Basicio)\n",
        "    - Image Represenation in OpenCV\n",
        "2. [Basic Operations](#Basicops)\n",
        "    - [Convert](#conv)\n",
        "    - [Colorspaces](#clsp)\n",
        "    - [Resize](#res)\n",
        "    - [Flip](#flip)\n",
        "    - [Rotate](#flip)\n",
        "    - [Crop](#crp)\n",
        "3. [Mathematical and Logical Operations on Images](#mathops)\n",
        "    - [Artihmatic Operations](#arith)\n",
        "    - [Logical Operations](#lgic)\n",
        "4. [Image Enhancement](#imgenhc)\n",
        "    - [Log Transform](#lg-trans)\n",
        "    - [Power-law(Gamma) transformations](#pow-trans)\n",
        "    - [Contrast Stretching](#con-strh)\n",
        "    - [Histogram Equalization](#hist-eq)\n",
        "    - [Spatial & Linear Filtering](#fltr)\n",
        "5. [Morphological Image Processing](#morph)\n",
        "6. [Geometric Operations](#geops)\n",
        "    - [Affine Transformation](#aft)\n",
        "    - [Perspective Transformation](#pst)\n",
        "7. [Image Segmentation/Object Detection](#img-seg)\n",
        "    - [Color or shape based object detection](#clr-objdet)\n",
        "    - [Point Detect](#pt-objdet)\n",
        "    - [Line Detect](#ln-objdet)\n",
        "    - [Edge Detect](#edg-objdet)\n",
        "    - [Hough Trabsform](#houg)\n",
        "    - [Region-Based Segmentation]\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F2z1QwczMhpJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Imports\n",
        "\n",
        "import os\n",
        "import sys\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "import cv2\n",
        "\n",
        "import ipywidgets as widgets\n",
        "from ipywidgets import interact, interact_manual"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_bypcdwDMhpW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Get Python and OpenCV Version\n",
        "\n",
        "print('OpenCV-Python Lib Version:', cv2.__version__)\n",
        "print('Python Version:',sys.version)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jx5f2SnOMhpf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Sample Images\n",
        "\n",
        "# !git clone https://github.com/MeAmarP/sample_imgs.git\n",
        "os.listdir(os.path.join(os.getcwd(), 'sample_imgs'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "SHx47TLPP3W1"
      },
      "source": [
        "\n",
        "## 1. I/O: Read,Show,Write Images <a name=\"Basicio\"></a>\n",
        "### Types of Images:\n",
        "+ Binary : 2D Array of pixels,where Pixel Value is either 0 or 255.\n",
        "+ Grayscale : 2D Array of pixels,where Pixel Value is anything between 0-255 \n",
        "+ RGB/TrueColor : 3D Array of pixels,where Pixel Value is anything between 0-255 \n",
        "\n",
        "Note: RGB pixel format is quit standard among MATLAB or other image processing liberaies, but OpenCV uses BGR pixel format."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5iz5cR7uMhpq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "MainImgBin = cv2.imread('sample_imgs/cells_bin.png',cv2.IMREAD_UNCHANGED)\n",
        "MainImgBGR = cv2.imread('sample_imgs/fruitbowl_rgb.jpg',cv2.IMREAD_UNCHANGED)\n",
        "MainImgGray = cv2.imread('sample_imgs/alg_gry.jpg',cv2.IMREAD_UNCHANGED)\n",
        "\n",
        "print('DatatypeClass of Image:',type(MainImgBGR))\n",
        "print('Shape/Size of RGB Img:', MainImgBGR.shape)\n",
        "print('Shape/Size of Gray Img:', MainImgGray.shape)\n",
        "print('Shape/Size of Binary Img:', MainImgBin.shape)\n",
        "\n",
        "plt.figure(figsize=(20,10))\n",
        "plt.subplot(1,3,1)\n",
        "#Note: matplotlib uses RGB format so had to convert BGR-to-RGB\n",
        "plt.imshow(cv2.cvtColor(MainImgBGR,cv2.COLOR_BGR2RGB))\n",
        "plt.title('RGB Image',color='c')\n",
        "plt.subplot(1,3,2)\n",
        "plt.imshow(MainImgGray,cmap='gray')\n",
        "plt.title('Grayscale Image',color='c')\n",
        "plt.subplot(1,3,3)\n",
        "plt.imshow(MainImgBin)\n",
        "plt.title('Binary Image',color='c')\n",
        "plt.show()\n",
        "\n",
        "# Why use cv2.IMREAD_UNCHANGED with IMREAD?\n",
        "# https://stackoverflow.com/a/18871394\n",
        "# https://docs.opencv.org/3.4.3/d4/da8/group__imgcodecs.html#gga292d81be8d76901bff7988d18d2b42acae80c3e72393ec86b8ea1db4a2a228b5f"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "e_4YdS-HPF5o"
      },
      "source": [
        "## 2. Basic Operations: <a name=\"Basicops\"></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "teGjNWG4Mhpy",
        "colab_type": "text"
      },
      "source": [
        "### Convert: <a name=\"conv\"></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "YwQsJg5jMhp0",
        "colab_type": "code",
        "outputId": "7b71b129-86f3-45e2-a85f-df65920905ac",
        "colab": {}
      },
      "source": [
        "#Convert to Gray\n",
        "img_gry = cv2.cvtColor(MainImgBGR,cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "#Convert to Binary\n",
        "# Method: Basic Thresholding\n",
        "ret,img_bin = cv2.threshold(img_gry,127,255,cv2.THRESH_BINARY)\n",
        "ret,img_bininv = cv2.threshold(img_gry,127,255,cv2.THRESH_BINARY_INV)\n",
        "\n",
        "# Method: Adaptive Thresholding\n",
        "img_adp_gusbin = cv2.adaptiveThreshold(img_gry,255,cv2.ADAPTIVE_THRESH_GAUSSIAN_C,cv2.THRESH_BINARY,5,5)\n",
        "img_adp_meanbin = cv2.adaptiveThreshold(img_gry,255,cv2.ADAPTIVE_THRESH_MEAN_C,cv2.THRESH_BINARY,5,5)\n",
        "\n",
        "# Method: Otsu's Thresholding\n",
        "ret,img_Otsubin = cv2.threshold(img_gry,127,255,cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n",
        "\n",
        "plt.imshow(img_Otsubin,cmap='binary')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7feac775b4e0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "image/svg+xml": "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Created with matplotlib (https://matplotlib.org/) -->\n<svg height=\"252.143392pt\" version=\"1.1\" viewBox=\"0 0 377.97534 252.143392\" width=\"377.97534pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n <defs>\n  <style type=\"text/css\">\n*{stroke-linecap:butt;stroke-linejoin:round;}\n  </style>\n </defs>\n <g id=\"figure_1\">\n  <g id=\"patch_1\">\n   <path d=\"M 0 252.143392 \nL 377.97534 252.143392 \nL 377.97534 0 \nL 0 0 \nz\n\" style=\"fill:none;\"/>\n  </g>\n  <g id=\"axes_1\">\n   <g id=\"patch_2\">\n    <path d=\"M 33.2875 228.265267 \nL 367.27534 228.265267 \nL 367.27534 10.825267 \nL 33.2875 10.825267 \nz\n\"/>\n   </g>\n   <g clip-path=\"url(#pdb8dafdb30)\">\n    <image height=\"218\" id=\"imagefd33393fae\" transform=\"scale(1 -1)translate(0 -218)\" width=\"334\" x=\"33.2875\" xlink:href=\"data:image/png;base64,\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\" y=\"-10.265267\"/>\n   </g>\n   <g id=\"matplotlib.axis_1\">\n    <g id=\"xtick_1\">\n     <g id=\"line2d_1\">\n      <defs>\n       <path d=\"M 0 0 \nL 0 3.5 \n\" id=\"m2c354fe667\" style=\"stroke:#ffffff;stroke-width:0.8;\"/>\n      </defs>\n      <g>\n       <use style=\"fill:#ffffff;stroke:#ffffff;stroke-width:0.8;\" x=\"33.461452\" xlink:href=\"#m2c354fe667\" y=\"228.265267\"/>\n      </g>\n     </g>\n     <g id=\"text_1\">\n      <!-- 0 -->\n      <defs>\n       <path d=\"M 31.78125 66.40625 \nQ 24.171875 66.40625 20.328125 58.90625 \nQ 16.5 51.421875 16.5 36.375 \nQ 16.5 21.390625 20.328125 13.890625 \nQ 24.171875 6.390625 31.78125 6.390625 \nQ 39.453125 6.390625 43.28125 13.890625 \nQ 47.125 21.390625 47.125 36.375 \nQ 47.125 51.421875 43.28125 58.90625 \nQ 39.453125 66.40625 31.78125 66.40625 \nz\nM 31.78125 74.21875 \nQ 44.046875 74.21875 50.515625 64.515625 \nQ 56.984375 54.828125 56.984375 36.375 \nQ 56.984375 17.96875 50.515625 8.265625 \nQ 44.046875 -1.421875 31.78125 -1.421875 \nQ 19.53125 -1.421875 13.0625 8.265625 \nQ 6.59375 17.96875 6.59375 36.375 \nQ 6.59375 54.828125 13.0625 64.515625 \nQ 19.53125 74.21875 31.78125 74.21875 \nz\n\" id=\"DejaVuSans-48\"/>\n      </defs>\n      <g style=\"fill:#ffffff;\" transform=\"translate(30.280202 242.863704)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_2\">\n     <g id=\"line2d_2\">\n      <g>\n       <use style=\"fill:#ffffff;stroke:#ffffff;stroke-width:0.8;\" x=\"103.042252\" xlink:href=\"#m2c354fe667\" y=\"228.265267\"/>\n      </g>\n     </g>\n     <g id=\"text_2\">\n      <!-- 200 -->\n      <defs>\n       <path d=\"M 19.1875 8.296875 \nL 53.609375 8.296875 \nL 53.609375 0 \nL 7.328125 0 \nL 7.328125 8.296875 \nQ 12.9375 14.109375 22.625 23.890625 \nQ 32.328125 33.6875 34.8125 36.53125 \nQ 39.546875 41.84375 41.421875 45.53125 \nQ 43.3125 49.21875 43.3125 52.78125 \nQ 43.3125 58.59375 39.234375 62.25 \nQ 35.15625 65.921875 28.609375 65.921875 \nQ 23.96875 65.921875 18.8125 64.3125 \nQ 13.671875 62.703125 7.8125 59.421875 \nL 7.8125 69.390625 \nQ 13.765625 71.78125 18.9375 73 \nQ 24.125 74.21875 28.421875 74.21875 \nQ 39.75 74.21875 46.484375 68.546875 \nQ 53.21875 62.890625 53.21875 53.421875 \nQ 53.21875 48.921875 51.53125 44.890625 \nQ 49.859375 40.875 45.40625 35.40625 \nQ 44.1875 33.984375 37.640625 27.21875 \nQ 31.109375 20.453125 19.1875 8.296875 \nz\n\" id=\"DejaVuSans-50\"/>\n      </defs>\n      <g style=\"fill:#ffffff;\" transform=\"translate(93.498502 242.863704)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-50\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_3\">\n     <g id=\"line2d_3\">\n      <g>\n       <use style=\"fill:#ffffff;stroke:#ffffff;stroke-width:0.8;\" x=\"172.623052\" xlink:href=\"#m2c354fe667\" y=\"228.265267\"/>\n      </g>\n     </g>\n     <g id=\"text_3\">\n      <!-- 400 -->\n      <defs>\n       <path d=\"M 37.796875 64.3125 \nL 12.890625 25.390625 \nL 37.796875 25.390625 \nz\nM 35.203125 72.90625 \nL 47.609375 72.90625 \nL 47.609375 25.390625 \nL 58.015625 25.390625 \nL 58.015625 17.1875 \nL 47.609375 17.1875 \nL 47.609375 0 \nL 37.796875 0 \nL 37.796875 17.1875 \nL 4.890625 17.1875 \nL 4.890625 26.703125 \nz\n\" id=\"DejaVuSans-52\"/>\n      </defs>\n      <g style=\"fill:#ffffff;\" transform=\"translate(163.079302 242.863704)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-52\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_4\">\n     <g id=\"line2d_4\">\n      <g>\n       <use style=\"fill:#ffffff;stroke:#ffffff;stroke-width:0.8;\" x=\"242.203852\" xlink:href=\"#m2c354fe667\" y=\"228.265267\"/>\n      </g>\n     </g>\n     <g id=\"text_4\">\n      <!-- 600 -->\n      <defs>\n       <path d=\"M 33.015625 40.375 \nQ 26.375 40.375 22.484375 35.828125 \nQ 18.609375 31.296875 18.609375 23.390625 \nQ 18.609375 15.53125 22.484375 10.953125 \nQ 26.375 6.390625 33.015625 6.390625 \nQ 39.65625 6.390625 43.53125 10.953125 \nQ 47.40625 15.53125 47.40625 23.390625 \nQ 47.40625 31.296875 43.53125 35.828125 \nQ 39.65625 40.375 33.015625 40.375 \nz\nM 52.59375 71.296875 \nL 52.59375 62.3125 \nQ 48.875 64.0625 45.09375 64.984375 \nQ 41.3125 65.921875 37.59375 65.921875 \nQ 27.828125 65.921875 22.671875 59.328125 \nQ 17.53125 52.734375 16.796875 39.40625 \nQ 19.671875 43.65625 24.015625 45.921875 \nQ 28.375 48.1875 33.59375 48.1875 \nQ 44.578125 48.1875 50.953125 41.515625 \nQ 57.328125 34.859375 57.328125 23.390625 \nQ 57.328125 12.15625 50.6875 5.359375 \nQ 44.046875 -1.421875 33.015625 -1.421875 \nQ 20.359375 -1.421875 13.671875 8.265625 \nQ 6.984375 17.96875 6.984375 36.375 \nQ 6.984375 53.65625 15.1875 63.9375 \nQ 23.390625 74.21875 37.203125 74.21875 \nQ 40.921875 74.21875 44.703125 73.484375 \nQ 48.484375 72.75 52.59375 71.296875 \nz\n\" id=\"DejaVuSans-54\"/>\n      </defs>\n      <g style=\"fill:#ffffff;\" transform=\"translate(232.660102 242.863704)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-54\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_5\">\n     <g id=\"line2d_5\">\n      <g>\n       <use style=\"fill:#ffffff;stroke:#ffffff;stroke-width:0.8;\" x=\"311.784652\" xlink:href=\"#m2c354fe667\" y=\"228.265267\"/>\n      </g>\n     </g>\n     <g id=\"text_5\">\n      <!-- 800 -->\n      <defs>\n       <path d=\"M 31.78125 34.625 \nQ 24.75 34.625 20.71875 30.859375 \nQ 16.703125 27.09375 16.703125 20.515625 \nQ 16.703125 13.921875 20.71875 10.15625 \nQ 24.75 6.390625 31.78125 6.390625 \nQ 38.8125 6.390625 42.859375 10.171875 \nQ 46.921875 13.96875 46.921875 20.515625 \nQ 46.921875 27.09375 42.890625 30.859375 \nQ 38.875 34.625 31.78125 34.625 \nz\nM 21.921875 38.8125 \nQ 15.578125 40.375 12.03125 44.71875 \nQ 8.5 49.078125 8.5 55.328125 \nQ 8.5 64.0625 14.71875 69.140625 \nQ 20.953125 74.21875 31.78125 74.21875 \nQ 42.671875 74.21875 48.875 69.140625 \nQ 55.078125 64.0625 55.078125 55.328125 \nQ 55.078125 49.078125 51.53125 44.71875 \nQ 48 40.375 41.703125 38.8125 \nQ 48.828125 37.15625 52.796875 32.3125 \nQ 56.78125 27.484375 56.78125 20.515625 \nQ 56.78125 9.90625 50.3125 4.234375 \nQ 43.84375 -1.421875 31.78125 -1.421875 \nQ 19.734375 -1.421875 13.25 4.234375 \nQ 6.78125 9.90625 6.78125 20.515625 \nQ 6.78125 27.484375 10.78125 32.3125 \nQ 14.796875 37.15625 21.921875 38.8125 \nz\nM 18.3125 54.390625 \nQ 18.3125 48.734375 21.84375 45.5625 \nQ 25.390625 42.390625 31.78125 42.390625 \nQ 38.140625 42.390625 41.71875 45.5625 \nQ 45.3125 48.734375 45.3125 54.390625 \nQ 45.3125 60.0625 41.71875 63.234375 \nQ 38.140625 66.40625 31.78125 66.40625 \nQ 25.390625 66.40625 21.84375 63.234375 \nQ 18.3125 60.0625 18.3125 54.390625 \nz\n\" id=\"DejaVuSans-56\"/>\n      </defs>\n      <g style=\"fill:#ffffff;\" transform=\"translate(302.240902 242.863704)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-56\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n   </g>\n   <g id=\"matplotlib.axis_2\">\n    <g id=\"ytick_1\">\n     <g id=\"line2d_6\">\n      <defs>\n       <path d=\"M 0 0 \nL -3.5 0 \n\" id=\"md7017a0922\" style=\"stroke:#ffffff;stroke-width:0.8;\"/>\n      </defs>\n      <g>\n       <use style=\"fill:#ffffff;stroke:#ffffff;stroke-width:0.8;\" x=\"33.2875\" xlink:href=\"#md7017a0922\" y=\"10.999219\"/>\n      </g>\n     </g>\n     <g id=\"text_6\">\n      <!-- 0 -->\n      <g style=\"fill:#ffffff;\" transform=\"translate(19.925 14.798437)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_2\">\n     <g id=\"line2d_7\">\n      <g>\n       <use style=\"fill:#ffffff;stroke:#ffffff;stroke-width:0.8;\" x=\"33.2875\" xlink:href=\"#md7017a0922\" y=\"45.789619\"/>\n      </g>\n     </g>\n     <g id=\"text_7\">\n      <!-- 100 -->\n      <defs>\n       <path d=\"M 12.40625 8.296875 \nL 28.515625 8.296875 \nL 28.515625 63.921875 \nL 10.984375 60.40625 \nL 10.984375 69.390625 \nL 28.421875 72.90625 \nL 38.28125 72.90625 \nL 38.28125 8.296875 \nL 54.390625 8.296875 \nL 54.390625 0 \nL 12.40625 0 \nz\n\" id=\"DejaVuSans-49\"/>\n      </defs>\n      <g style=\"fill:#ffffff;\" transform=\"translate(7.2 49.588837)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_3\">\n     <g id=\"line2d_8\">\n      <g>\n       <use style=\"fill:#ffffff;stroke:#ffffff;stroke-width:0.8;\" x=\"33.2875\" xlink:href=\"#md7017a0922\" y=\"80.580019\"/>\n      </g>\n     </g>\n     <g id=\"text_8\">\n      <!-- 200 -->\n      <g style=\"fill:#ffffff;\" transform=\"translate(7.2 84.379237)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-50\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_4\">\n     <g id=\"line2d_9\">\n      <g>\n       <use style=\"fill:#ffffff;stroke:#ffffff;stroke-width:0.8;\" x=\"33.2875\" xlink:href=\"#md7017a0922\" y=\"115.370419\"/>\n      </g>\n     </g>\n     <g id=\"text_9\">\n      <!-- 300 -->\n      <defs>\n       <path d=\"M 40.578125 39.3125 \nQ 47.65625 37.796875 51.625 33 \nQ 55.609375 28.21875 55.609375 21.1875 \nQ 55.609375 10.40625 48.1875 4.484375 \nQ 40.765625 -1.421875 27.09375 -1.421875 \nQ 22.515625 -1.421875 17.65625 -0.515625 \nQ 12.796875 0.390625 7.625 2.203125 \nL 7.625 11.71875 \nQ 11.71875 9.328125 16.59375 8.109375 \nQ 21.484375 6.890625 26.8125 6.890625 \nQ 36.078125 6.890625 40.9375 10.546875 \nQ 45.796875 14.203125 45.796875 21.1875 \nQ 45.796875 27.640625 41.28125 31.265625 \nQ 36.765625 34.90625 28.71875 34.90625 \nL 20.21875 34.90625 \nL 20.21875 43.015625 \nL 29.109375 43.015625 \nQ 36.375 43.015625 40.234375 45.921875 \nQ 44.09375 48.828125 44.09375 54.296875 \nQ 44.09375 59.90625 40.109375 62.90625 \nQ 36.140625 65.921875 28.71875 65.921875 \nQ 24.65625 65.921875 20.015625 65.03125 \nQ 15.375 64.15625 9.8125 62.3125 \nL 9.8125 71.09375 \nQ 15.4375 72.65625 20.34375 73.4375 \nQ 25.25 74.21875 29.59375 74.21875 \nQ 40.828125 74.21875 47.359375 69.109375 \nQ 53.90625 64.015625 53.90625 55.328125 \nQ 53.90625 49.265625 50.4375 45.09375 \nQ 46.96875 40.921875 40.578125 39.3125 \nz\n\" id=\"DejaVuSans-51\"/>\n      </defs>\n      <g style=\"fill:#ffffff;\" transform=\"translate(7.2 119.169637)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-51\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_5\">\n     <g id=\"line2d_10\">\n      <g>\n       <use style=\"fill:#ffffff;stroke:#ffffff;stroke-width:0.8;\" x=\"33.2875\" xlink:href=\"#md7017a0922\" y=\"150.160819\"/>\n      </g>\n     </g>\n     <g id=\"text_10\">\n      <!-- 400 -->\n      <g style=\"fill:#ffffff;\" transform=\"translate(7.2 153.960037)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-52\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_6\">\n     <g id=\"line2d_11\">\n      <g>\n       <use style=\"fill:#ffffff;stroke:#ffffff;stroke-width:0.8;\" x=\"33.2875\" xlink:href=\"#md7017a0922\" y=\"184.951219\"/>\n      </g>\n     </g>\n     <g id=\"text_11\">\n      <!-- 500 -->\n      <defs>\n       <path d=\"M 10.796875 72.90625 \nL 49.515625 72.90625 \nL 49.515625 64.59375 \nL 19.828125 64.59375 \nL 19.828125 46.734375 \nQ 21.96875 47.46875 24.109375 47.828125 \nQ 26.265625 48.1875 28.421875 48.1875 \nQ 40.625 48.1875 47.75 41.5 \nQ 54.890625 34.8125 54.890625 23.390625 \nQ 54.890625 11.625 47.5625 5.09375 \nQ 40.234375 -1.421875 26.90625 -1.421875 \nQ 22.3125 -1.421875 17.546875 -0.640625 \nQ 12.796875 0.140625 7.71875 1.703125 \nL 7.71875 11.625 \nQ 12.109375 9.234375 16.796875 8.0625 \nQ 21.484375 6.890625 26.703125 6.890625 \nQ 35.15625 6.890625 40.078125 11.328125 \nQ 45.015625 15.765625 45.015625 23.390625 \nQ 45.015625 31 40.078125 35.4375 \nQ 35.15625 39.890625 26.703125 39.890625 \nQ 22.75 39.890625 18.8125 39.015625 \nQ 14.890625 38.140625 10.796875 36.28125 \nz\n\" id=\"DejaVuSans-53\"/>\n      </defs>\n      <g style=\"fill:#ffffff;\" transform=\"translate(7.2 188.750437)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-53\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_7\">\n     <g id=\"line2d_12\">\n      <g>\n       <use style=\"fill:#ffffff;stroke:#ffffff;stroke-width:0.8;\" x=\"33.2875\" xlink:href=\"#md7017a0922\" y=\"219.741619\"/>\n      </g>\n     </g>\n     <g id=\"text_12\">\n      <!-- 600 -->\n      <g style=\"fill:#ffffff;\" transform=\"translate(7.2 223.540837)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-54\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n   </g>\n   <g id=\"patch_3\">\n    <path d=\"M 33.2875 228.265267 \nL 33.2875 10.825267 \n\" style=\"fill:none;stroke:#ffffff;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_4\">\n    <path d=\"M 367.27534 228.265267 \nL 367.27534 10.825267 \n\" style=\"fill:none;stroke:#ffffff;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_5\">\n    <path d=\"M 33.2875 228.265267 \nL 367.27534 228.265267 \n\" style=\"fill:none;stroke:#ffffff;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_6\">\n    <path d=\"M 33.2875 10.825267 \nL 367.27534 10.825267 \n\" style=\"fill:none;stroke:#ffffff;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n  </g>\n </g>\n <defs>\n  <clipPath id=\"pdb8dafdb30\">\n   <rect height=\"217.44\" width=\"333.98784\" x=\"33.2875\" y=\"10.825267\"/>\n  </clipPath>\n </defs>\n</svg>\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "dark"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7LEYaCWKMhp6",
        "colab_type": "text"
      },
      "source": [
        "### Convert Colorspaces: <a name=\"clsp\"></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YMiNJy2KMhp8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Changing Color Spaces\n",
        "img_hls = cv2.cvtColor(MainImgBGR,cv2.COLOR_BGR2HLS)\n",
        "img_hsv = cv2.cvtColor(MainImgBGR,cv2.COLOR_BGR2HSV)\n",
        "img_lab = cv2.cvtColor(MainImgBGR,cv2.COLOR_BGR2LAB)\n",
        "img_yuv = cv2.cvtColor(MainImgBGR,cv2.COLOR_BGR2YUV)\n",
        "plt.imshow(img_hsv)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EBxAenXTMhqD",
        "colab_type": "text"
      },
      "source": [
        "### Resize Image <a name=\"res\"></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ggg0QoYaMhqG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#\n",
        "IMG_WIDTH = 400\n",
        "IMG_HEIGHT = 400\n",
        "img = cv2.imread('sample_imgs/fruitbowl_rgb.jpg')\n",
        "print('Before Resize: ',img.shape[:2])\n",
        "\n",
        "#Try Other Interploation Methods too\n",
        "re1_img = cv2.resize(img,(IMG_WIDTH,IMG_HEIGHT),interpolation=cv2.INTER_LANCZOS4)\n",
        "re2_img = cv2.resize(img,(IMG_WIDTH*2,IMG_HEIGHT),interpolation=cv2.INTER_AREA)\n",
        "print('After Resize 1: ',re1_img.shape[:2])\n",
        "print('After Resize 2: ',re2_img.shape[:2])\n",
        "plt.figure(figsize=(10,10))\n",
        "plt.subplot(1,3,1)\n",
        "plt.imshow(img)\n",
        "plt.subplot(1,3,2)\n",
        "plt.imshow(re1_img)\n",
        "plt.subplot(1,3,3)\n",
        "plt.imshow(re2_img)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JUx1j_wTMhqL",
        "colab_type": "text"
      },
      "source": [
        "### Flip/Rotate Images <a name=\"flip\"></a>\n",
        "*interactive*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cgznUwSMMhqN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "@interact_manual(angle_val=widgets.IntSlider(min=0, max=360, step=5, value=10))\n",
        "def rotate_img(angle_val):\n",
        "    path_to_grayscale_img = 'sample_imgs/lena_gry.bmp'\n",
        "    scaleFactor = 1\n",
        "    img = cv2.imread(path_to_grayscale_img,cv2.IMREAD_UNCHANGED)\n",
        "    rows,cols = img.shape\n",
        "    imgCenter = (cols-1)/2.0,(rows-1)/2.0\n",
        "    #Calculate an affine matrix of 2D rotation. \n",
        "    rotateMat = cv2.getRotationMatrix2D(imgCenter,angle_val,scaleFactor)\n",
        "    # Apply an affine transformation to an image. \n",
        "    out_img = cv2.warpAffine(img,rotateMat,(cols,rows))\n",
        "    plt.figure(figsize=(10,10))\n",
        "    plt.subplot(1,2,1), plt.imshow(img,cmap='gray') ,plt.title('Original Image',color='c')\n",
        "    plt.subplot(1,2,2), plt.imshow(out_img,cmap='gray'), plt.title('Rotated Image',color='c')\n",
        "    plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UWpsxVbyMhqS",
        "colab_type": "text"
      },
      "source": [
        "### Crop Images <a name=\"crp\"></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VA0xsO4_MhqU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#\n",
        "#Note is more about array slicing. refer row & column vals from x,y-axis for ROI.\n",
        "img = cv2.imread('sample_imgs/tank_gry.tiff',cv2.IMREAD_UNCHANGED)\n",
        "\n",
        "#Slicing using ROI\n",
        "cropped = img[150:350,150:310].copy()\n",
        "plt.subplot(121),plt.imshow(img,cmap='gray'),plt.title('Original',color='c')\n",
        "plt.subplot(122),plt.imshow(cropped,cmap='gray'),plt.title('Cropped',color='c')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y5X3IQ9CMhqZ",
        "colab_type": "text"
      },
      "source": [
        "## 3. Mathematical and Logical Operations on Images <a name=\"mathops\"></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A7-EXqPiMhqb",
        "colab_type": "text"
      },
      "source": [
        "### Artihmatic Operations <a name=\"arith\"></a>\n",
        "*interactive*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "84PZ9909Mhqd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Math_Ops = Add, Subtract, Multiply, Divide\n",
        "BasicArithOps = ['add','subtract','multiply','divide']\n",
        "\n",
        "@interact_manual(arith_op=BasicArithOps,para_val=widgets.IntSlider(min=1, max=100, step=1, value=10))\n",
        "def arithops_on_img(arith_op,para_val):\n",
        "  img = cv2.imread('sample_imgs/lena_gry.bmp',cv2.IMREAD_UNCHANGED)\n",
        "  if arith_op == 'add':\n",
        "    s_img = img + para_val\n",
        "  elif arith_op == 'subtract':\n",
        "    s_img = img - para_val\n",
        "  elif arith_op == 'multiply':\n",
        "    s_img = img * para_val\n",
        "  elif arith_op == 'divide':\n",
        "    #Use Floor Divison operator\n",
        "    s_img = img // para_val\n",
        "  plt.figure(figsize=(10,10))\n",
        "  plt.subplot(121),plt.imshow(img,cmap='gray'),plt.title('Original',color='c')\n",
        "  plt.subplot(122),plt.imshow(s_img,cmap='gray'),plt.title('Math Operation',color='c')\n",
        "  plt.show()\n",
        "\n",
        "img,s_img = arithops_on_img('add',100)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dfQXymCmMhqi",
        "colab_type": "text"
      },
      "source": [
        "### Logical Operations <a name=\"lgic\"></a>\n",
        "*interactive*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "npO4mD5gWSt5",
        "colab": {}
      },
      "source": [
        "#Logical/Bitwise Operations\n",
        "path_to_grayscale_img = 'sample_imgs/lena_gry.bmp'\n",
        "LogicalOps = ['and','or','xor','not']\n",
        "\n",
        "@interact_manual(logical_op=LogicalOps)\n",
        "def logicalops_on_img(logical_op):\n",
        "    img = cv2.imread(path_to_grayscale_img)\n",
        "    h,w,_ = img.shape\n",
        "    mask_img = np.concatenate((np.zeros(shape=[h,(w//3),3],dtype=np.uint8),\n",
        "                              np.ones(shape=[h,(w//3)+2,3],dtype=np.uint8)*127,\n",
        "                              np.ones(shape=[h,(w//3),3],dtype=np.uint8)*255),\n",
        "                              axis=1)\n",
        "    if logical_op == 'and':\n",
        "        print('Performed Bitwise AND')\n",
        "        result_img = cv2.bitwise_and(img,mask_img)        \n",
        "    elif logical_op == 'or':\n",
        "        print('Performed Bitwise OR')\n",
        "        result_img = cv2.bitwise_or(img,mask_img)\n",
        "    elif logical_op == 'xor':\n",
        "        print('Performed Bitwise XOR')\n",
        "        result_img = cv2.bitwise_xor(img,mask_img)\n",
        "    elif logical_op == 'not':\n",
        "        print('Performed Bitwise NOT')\n",
        "        result_img = cv2.bitwise_not(img)        \n",
        "    plt.figure(figsize=(10,10))\n",
        "    plt.subplot(131),plt.imshow(img,cmap='gray'),plt.title('Original',color='c')\n",
        "    plt.subplot(132),plt.imshow(mask_img,cmap='gray'),plt.title('Mask',color='c')\n",
        "    plt.subplot(133),plt.imshow(result_img,cmap='gray'),plt.title('Processed Image',color='c')\n",
        "    plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yQ4sYFt3Mhqo",
        "colab_type": "text"
      },
      "source": [
        "## 4. Image Enhancement <a name=\"imgenhc\"></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sy2Io7fQMhqq",
        "colab_type": "text"
      },
      "source": [
        "### Log Transform <a name=\"lg-trans\"></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CC7aftqPMhqr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "path_to_img = 'sample_imgs/tank_gry.tiff'\n",
        "def applyLogTransform(path_to_img):\n",
        "    img = cv2.imread(path_to_img,cv2.IMREAD_UNCHANGED)\n",
        "    hist_img = cv2.calcHist([img],[0],None,[256],[0,256])\n",
        "    img_log = (np.log(img+1)/(np.log(1+np.max(img))))*255\n",
        "    img_log = np.array(img_log,dtype=np.uint8)\n",
        "    hist_img_log = cv2.calcHist([img_log],[0],None,[256],[0,256])\n",
        "\n",
        "    plt.figure(figsize=(20,10))\n",
        "    plt.subplot(221),plt.imshow(img,cmap='gray'),plt.title('Original Img',color='c')\n",
        "    plt.subplot(222),plt.plot(hist_img),plt.title('Histogram: Before',color='c')\n",
        "    plt.subplot(223),plt.imshow(img_log,cmap='gray'),plt.title('Log Transformed Img',color='c')\n",
        "    plt.subplot(224),plt.plot(hist_img_log),plt.title('Histogram: After',color='c')\n",
        "    plt.show()\n",
        "    return"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xtu6eOkmMhq0",
        "colab_type": "text"
      },
      "source": [
        "### Gamma Trasform <a name=\"pow-trans\"></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "65G-UwacMhq4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "path_to_img = 'sample_imgs/tank_gry.tiff'\n",
        "\n",
        "#gamma_vals = [0.1, 0.5, 1.2, 2.2]\n",
        "def applyGammaTransform(path_to_img,gamma_val=None):\n",
        "    img = cv2.imread(path_to_img,cv2.IMREAD_UNCHANGED)\n",
        "    hist_img = cv2.calcHist([img],[0],None,[256],[0,256])\n",
        "    gamma_corrected = np.array(255*(img / 255) ** gamma_val, dtype = 'uint8')\n",
        "    hist_img_gamma = cv2.calcHist([gamma_corrected],[0],None,[256],[0,256])\n",
        "\n",
        "    plt.figure(figsize=(20,10))\n",
        "    plt.subplot(221),plt.imshow(img,cmap='gray'),plt.title('Original Img',color='c')\n",
        "    plt.subplot(222),plt.plot(hist_img),plt.title('Histogram: Before',color='c')\n",
        "    plt.subplot(223),plt.imshow(gamma_corrected,cmap='gray'),plt.title('Gamma Transformed Img',color='c')\n",
        "    plt.subplot(224),plt.plot(hist_img_gamma),plt.title('Histogram: After',color='c')\n",
        "    plt.show()\n",
        "    return\n",
        "\n",
        "applyGammaTransform(path_to_img,gamma_val=0.8)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-iPLrzSgMhq8",
        "colab_type": "text"
      },
      "source": [
        "### Contrast Stretching <a name=\"con-strh\"></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jNwUO4QIMhq-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Apply \n",
        "# - MinMax Stretching\n",
        "path_to_img = r'sample_imgs\\lena_gry.bmp'\n",
        "\n",
        "def applyContrastStretching(path_to_img):\n",
        "    img = cv2.imread(path_to_img,cv2.IMREAD_UNCHANGED)\n",
        "    minmax_img = np.zeros((img.shape[0],img.shape[1]),dtype='uint8')\n",
        "    \n",
        "    for r in range(img.shape[0]):\n",
        "        for c in range(img.shape[1]):\n",
        "            minmax_img[r,c] = 255*(img[r,c]-np.min(img)) / (np.max(img)-np.min(img))\n",
        "    # minmax_img[:,:] = 255*(img[:,:]-np.min(img)) / (np.max(img)-np.min(img))\n",
        "    hist_img = cv2.calcHist([img],[0],None,[256],[0,256])\n",
        "    hist_contrast_stretch = cv2.calcHist([minmax_img],[0],None,[256],[0,256])\n",
        "    plt.figure(figsize=(10,10))\n",
        "    plt.subplot(221),plt.imshow(img,cmap='gray'),plt.title('Original Img',color='c')\n",
        "    plt.subplot(222),plt.plot(hist_img),plt.title('Histogram: Before',color='c')\n",
        "    plt.subplot(223),plt.imshow(minmax_img,cmap='gray'),plt.title('MinMax Contrast Stretching',color='c')\n",
        "    plt.subplot(224),plt.plot(hist_contrast_stretch),plt.title('Histogram: After',color='c')\n",
        "    return\n",
        "\n",
        "\n",
        "applyContrastStretching(path_to_img)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FNcHNikJMhrC",
        "colab_type": "text"
      },
      "source": [
        "### Histogram Equalization <a name=\"hist-eq\"></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YtuXczikMhrD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Histrogram Equalisation\n",
        "path_to_img = 'sample_imgs/lena_gry.bmp'\n",
        "\n",
        "def applyHistEqualization(path_to_img):\n",
        "    img = cv2.imread(path_to_img,cv2.IMREAD_GRAYSCALE)\n",
        "    img_histEq = cv2.equalizeHist(img)\n",
        "\n",
        "    hist_img = cv2.calcHist([img],[0],None,[256],[0,256])\n",
        "    hist_imgEqu = cv2.calcHist([img_histEq],[0],None,[256],[0,256])\n",
        "    plt.figure(figsize=(10,10))\n",
        "    plt.subplot(221),plt.imshow(img,cmap='gray'),plt.title('Original Img',color='c')\n",
        "    plt.subplot(222),plt.plot(hist_img),plt.title('Histogram: Before',color='c')\n",
        "    plt.subplot(223),plt.imshow(img_histEq,cmap='gray'),plt.title('Histogram Equalization',color='c')\n",
        "    plt.subplot(224),plt.plot(hist_imgEqu),plt.title('Histogram: After',color='c')\n",
        "    return\n",
        "\n",
        "def applyCLAHE(path_to_img):\n",
        "    img = cv2.imread(path_to_img,cv2.IMREAD_GRAYSCALE)\n",
        "    clahe = cv2.createCLAHE(clipLimit=0.8,tileGridSize=(8,8))\n",
        "    img_clahe = clahe.apply(img)\n",
        "\n",
        "    hist_img = cv2.calcHist([img],[0],None,[256],[0,256])\n",
        "    hist_imgClahe = cv2.calcHist([img_clahe],[0],None,[256],[0,256])\n",
        "\n",
        "    plt.figure(figsize=(10,10))\n",
        "    plt.subplot(221),plt.imshow(img,cmap='gray'),plt.title('Original Img',color='c')\n",
        "    plt.subplot(222),plt.plot(hist_img),plt.title('Histogram: Before',color='c')\n",
        "    plt.subplot(223),plt.imshow(img_clahe,cmap='gray'),plt.title('CLAHE',color='c')\n",
        "    plt.subplot(224),plt.plot(hist_imgClahe),plt.title('Histogram: Before',color='c')\n",
        "    return\n",
        "\n",
        "# applyHistEqualization(path_to_img)\n",
        "# applyCLAHE(path_to_img)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vZyjmgzaMhrI",
        "colab_type": "text"
      },
      "source": [
        "### Spatial & Linear Filtering <a name=\"fltr\"></a>\n",
        "+ blur() - Normalized Box Filter\n",
        "+ gaussianblur() - Gaussian\n",
        "+ medianblur() - Median\n",
        "+ filter2d() - Custom Arbitary Linear Filter\n",
        "+ bilateralfilter() - Bilateral Filter\n",
        "\n",
        "For detailed opencv documentation on filter methods visit link below> \n",
        "https://docs.opencv.org/4.1.0/d4/d86/group__imgproc__filter.html#ga27c049795ce870216ddfb366086b5a04"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zFoPLp9yMhrJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#filters/blurr Neighborhood Operations\n",
        "\n",
        "path_to_img = 'sample_imgs/lena_gry.bmp'\n",
        "\n",
        "def applyFilter(path_to_img,func_filter=None,kernel_len=None):\n",
        "    img = cv2.imread(path_to_img)\n",
        "    if img is None:\n",
        "        print('Unable to Read Image. Check you gave right path')\n",
        "        return -1\n",
        "    if func_filter == 'blur':\n",
        "        img_fltr = cv2.blur(img,(kernel_len,kernel_len))\n",
        "    if func_filter ==  'gaussian':\n",
        "        img_fltr = cv2.GaussianBlur(img,(kernel_len,kernel_len),0)\n",
        "    if func_filter == 'median':\n",
        "        #kernal_len should be odd and greater than 1\n",
        "        img_fltr = cv2.medianBlur(img,kernel_len)\n",
        "    if func_filter == 'bilateral':\n",
        "        img_fltr = cv2.bilateralFilter(img,kernel_len,kernel_len*2,kernel_len*2)\n",
        "    if func_filter == 'arbitary':\n",
        "        img_fltr =  cv2.filter2D(img,-1,kernel_len)\n",
        "\n",
        "    plt.figure(figsize=(10,10))\n",
        "    plt.subplot(121),plt.imshow(img,cmap='gray'),plt.title('Original Img',color='c')\n",
        "    plt.subplot(122),plt.imshow(img_fltr,cmap='gray'),plt.title((func_filter+' Filter Applied Img'),color='c')\n",
        "    return \n",
        "\n",
        "# applyFilter(path_to_img,func_filter='blur',kernel_len=5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-zg8JnUAMhrO",
        "colab_type": "text"
      },
      "source": [
        "### More Filters:\n",
        "+ Laplacian\n",
        "+ motion-vertical\n",
        "+ motion-horizontal"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iOVE_wyAMhrQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "path_to_img = 'sample_imgs/lena_gry.bmp'\n",
        "\n",
        "def applyMoreFilter(path_to_img,func_filter=None,kernel_len=None):\n",
        "    img = cv2.imread(path_to_img)\n",
        "\n",
        "    if func_filter == 'laplace':\n",
        "        img_fltr = cv2.Laplacian(img,-1,3)\n",
        "    if func_filter == 'motion-v':\n",
        "        kernel_verti = np.zeros((kernel_len,kernel_len))\n",
        "        kernel_verti[:, int((kernel_len - 1)/2)] = np.ones(kernel_len)\n",
        "        kernel_verti /= kernel_len\n",
        "        img_fltr = cv2.filter2D(img,-1,kernel_verti)\n",
        "    if func_filter == 'motion-h':\n",
        "        kernel_horiz = np.zeros((kernel_len,kernel_len))\n",
        "        kernel_horiz[int((kernel_len - 1)/2),:] = np.ones(kernel_len)\n",
        "        kernel_horiz /= kernel_len\n",
        "        img_fltr = cv2.filter2D(img,-1,kernel_horiz)\n",
        "\n",
        "    plt.figure(figsize=(10,10))\n",
        "    plt.subplot(121),plt.imshow(img,cmap='gray'),plt.title('Original Img',color='c')\n",
        "    plt.subplot(122),plt.imshow(img_fltr,cmap='gray'),plt.title((func_filter+' Filter Applied Img'),color='c')\n",
        "    return\n",
        "\n",
        "# applyMoreFilter(path_to_img,func_filter='motion-h',kernel_len=21)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LCGEow0mMhrT",
        "colab_type": "text"
      },
      "source": [
        "### 5. Morphological Transformations: <a name=\"morph\"></a>\n",
        "+ Erosion\n",
        "+ Dilation\n",
        "+ Opening\n",
        "+ Closing\n",
        "+ Morphological Gradient\n",
        "+ Top-Hat\n",
        "+ Black-Hat"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hG8M571YMhrY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#\n",
        "path_to_img = 'imgs/cells_bin.png'\n",
        "\n",
        "def applyMorphoTransform(path_to_img,morph_op=None,kernel_len=None,iters=None):\n",
        "    img = cv2.imread(path_to_img)\n",
        "    kernel = np.ones((kernel_len,kernel_len),np.uint8)\n",
        "\n",
        "    if morph_op == 'erode':\n",
        "        img_morph = cv2.erode(img,kernel,iterations=iters)\n",
        "    if morph_op == 'dilate':\n",
        "        img_morph = cv2.dilate(img,kernel,iterations= iters)\n",
        "    if morph_op == 'opening':\n",
        "        img_morph = cv2.morphologyEx(img, cv2.MORPH_OPEN, kernel)\n",
        "    if morph_op == 'closing':\n",
        "        img_morph = cv2.morphologyEx(img, cv2.MORPH_CLOSE, kernel)\n",
        "    if morph_op == 'morph_grad':\n",
        "        img_morph = cv2.morphologyEx(img, cv2.MORPH_GRADIENT, kernel)\n",
        "    if morph_op == 'top-hat':\n",
        "        img_morph = cv2.morphologyEx(img, cv2.MORPH_TOPHAT, kernel)\n",
        "    if morph_op == 'black-hat':\n",
        "        img_morph = cv2.morphologyEx(img, cv2.MORPH_BLACKHAT, kernel)\n",
        "    plt.figure(figsize=(20,10))\n",
        "    plt.subplot(121),plt.imshow(img,cmap='gray'),plt.title('Original Img',color='c')\n",
        "    plt.subplot(122),plt.imshow(img_morph,cmap='gray'),plt.title(morph_op+'applied Img',color='c')\n",
        "\n",
        "    return\n",
        "\n",
        "# applyMorphoTransform(path_to_img,morph_op='opening',kernel_len=5,iters=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wb4w3v5VMhrb",
        "colab_type": "text"
      },
      "source": [
        "## 6. Geometric Operations<a name=\"geops\"></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gm2llHFOMhrc",
        "colab_type": "text"
      },
      "source": [
        "### Affine Transformation <a name=\"aft\"></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Te_M6OYTMhrf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "path_to_img = 'imgs/bricks_in_wall_bin.tiff'\n",
        "img = cv2.imread(path_to_img,cv2.IMREAD_UNCHANGED)\n",
        "rows, cols = img.shape[:2]\n",
        "\n",
        "src_points = np.float32([[0,0], [cols-1,0], [0,rows-1]])\n",
        "dst_points = np.float32([[0,0], [int(0.5*(cols-1)),0], [int(0.5*(cols-1)),rows-1]])\n",
        "\n",
        "affine_matrix = cv2.getAffineTransform(src_points, dst_points)\n",
        "img_output = cv2.warpAffine(img, affine_matrix, (cols,rows))\n",
        "\n",
        "plt.figure(figsize=(20,10))\n",
        "plt.subplot(121),plt.imshow(img,cmap='gray'),plt.title('Original Img',color='c')\n",
        "plt.subplot(122),plt.imshow(img_output,cmap='gray'),plt.title('Transformed Img',color='c')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZUszBRv8Mhrj",
        "colab_type": "text"
      },
      "source": [
        "### Perspective Transformation<a name=\"pst\"></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8RJrRgnaMhrl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "path_to_img = 'imgs\\Baraja_de_UNO.jpg'\n",
        "\n",
        "img = cv2.imread(path_to_img)\n",
        "\n",
        "ptsMain = np.float32([[230,283],[347,234],[349,433],[472,370]])\n",
        "ptsTrans = np.float32([[0,0],[400,0],[0,400],[400,400]])\n",
        "\n",
        "mat = cv2.getPerspectiveTransform(ptsMain,ptsTrans)\n",
        "img_out = cv2.warpPerspective(img,mat,(400,400))\n",
        "\n",
        "for pt in ptsMain:\n",
        "    pt = tuple(pt)\n",
        "    img = cv2.circle(img,(tuple(pt)), 8, (255,0,0), -1)\n",
        "\n",
        "plt.figure(figsize=(20,10))\n",
        "plt.subplot(121),plt.imshow(img),plt.title('Input',color='c')\n",
        "plt.subplot(122),plt.imshow(img_out),plt.title('Transformed',color='c')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2_VXjkuZMhrp",
        "colab_type": "text"
      },
      "source": [
        "## 7. Image Segmentation:<a name=\"img-seg\"></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aPGkl4A_Mhrr",
        "colab_type": "text"
      },
      "source": [
        "### Point Detect <a name=\"pt-objdet\"></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TPRfO8XKMhrs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#POint Detection\n",
        "\n",
        "path_to_img = r'sample_imgs\\alg_gry.jpg'\n",
        "\n",
        "def pointDetctor(path_to_img):\n",
        "    img = cv2.imread(path_to_img)\n",
        "    kernel = np.float32([[-1,-1,-1],[-1,8,-1],[-1,-1,-1]])\n",
        "    img_out = cv2.filter2D(img,-1,kernel)\n",
        "    plt.figure(figsize=(20,10))\n",
        "    plt.subplot(121),plt.imshow(img),plt.title('Input',color='c')\n",
        "    plt.subplot(122),plt.imshow(img_out),plt.title('Transformed',color='c')\n",
        "    plt.show()\n",
        "    return\n",
        "pointDetctor(path_to_img)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tFq04WptMhry",
        "colab_type": "text"
      },
      "source": [
        "### Line Detection <a name=\"ln-objdet\"></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QGYsjKUjMhr0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "path_to_img = r'sample_imgs\\bricks_in_wall_bin.tiff'\n",
        "\n",
        "hori_line_mat = np.float32([[-1,-1,-1],\n",
        "                            [2,2,2],\n",
        "                            [-1,-1,-1]])\n",
        "\n",
        "verti_line_mat = np.float32([[-1,2,-1],\n",
        "                            [-1,2,-1],\n",
        "                            [-1,2,-1]])\n",
        "def lineDetector(path_to_img,kernel):\n",
        "    img = cv2.imread(path_to_img)\n",
        "    img_out = cv2.filter2D(img,-1,kernel)                        \n",
        "    plt.figure(figsize=(20,10))\n",
        "    plt.subplot(121),plt.imshow(img),plt.title('Input',color='c')\n",
        "    plt.subplot(122),plt.imshow(img_out),plt.title('Transformed',color='c')\n",
        "    plt.show()    \n",
        "    return\n",
        "lineDetector(path_to_img,verti_line_mat)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kv1Zu8O1Mhr4",
        "colab_type": "text"
      },
      "source": [
        "### Edge Detection<a name=\"edg-objdet\"></a>\n",
        "- sobel\n",
        "- prewitt\n",
        "- canny\n",
        "- roberts\n",
        "- scharr"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9c4PCGYIMhr4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "\n",
        "path_to_img = 'sample_imgs/lena_gry.bmp'\n",
        "algo_edgedetect = ['sobel', 'prewitt','canny','roberts','scharr']\n",
        "def edgeDetector(path_to_img,algo_edgedetect=None):\n",
        "    img = cv2.imread(path_to_img)\n",
        "    if algo_edgedetect == 'canny':\n",
        "        img_edge = cv2.Canny(img,100,200)\n",
        "    if algo_edgedetect == 'sobel':\n",
        "        img_edge = cv2.Sobel(img,-1,1,0,ksize=-1)\n",
        "    if algo_edgedetect == 'prewitt':\n",
        "        prewitt_kernel_h = np.array([[1,1,1],\n",
        "                                    [0,0,0],\n",
        "                                    [-1,-1,-1]])\n",
        "        prewitt_kernel_v = np.array([[-1,0,1],\n",
        "                                    [-1,0,1],\n",
        "                                    [-1,0,1]])\n",
        "        prewitt_h = cv2.filter2D(img,-1,prewitt_kernel_h)\n",
        "        prewitt_v = cv2.filter2D(img,-1,prewitt_kernel_v)\n",
        "        img_edge = prewitt_h + prewitt_v\n",
        "    if algo_edgedetect == 'roberts':\n",
        "        roberts_kernel_h = np.array([[-1,0],[0,1]])\n",
        "        roberts_kernel_v = np.array([[0,-1],[1,0]])\n",
        "        roberts_h_ele = cv2.filter2D(img,-1,roberts_kernel_h)\n",
        "        roberts_v_ele = cv2.filter2D(img,-1,roberts_kernel_v)\n",
        "        img_edge = roberts_h_ele + roberts_v_ele\n",
        "    if algo_edgedetect == 'scharr':\n",
        "        # img_gaussian = cv2.GaussianBlur(img,(3,3),5)\n",
        "        # img_edge = cv2.Laplacian(img_gaussian,-1)\n",
        "        img_edge = cv2.Scharr(img,-1,1,0)\n",
        "    # print(img_edge.dtype0\n",
        "    plt.figure(figsize=(20,10))\n",
        "    plt.subplot(121),plt.imshow(img),plt.title('Input',color='c')\n",
        "    plt.subplot(122),plt.imshow(img_edge),plt.title('Output',color='c')\n",
        "    plt.show()\n",
        "    return\n",
        "edgeDetector(path_to_img,algo_edgedetect='scharr')\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8B0y9pO7Mhr9",
        "colab_type": "text"
      },
      "source": [
        "### Hough Transforms:<a name=\"houg\"></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NtjQUpzgMhr-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Line Detection\n",
        "def houghLineDetector(path_to_img):\n",
        "    img = cv2.imread(path_to_img)\n",
        "    img_edge = cv2.Canny(img,80,200)\n",
        "    lines = cv2.HoughLinesP(img_edge,5,np.pi/180,20,minLineLength=50,maxLineGap=10)\n",
        "    for line in lines:\n",
        "        x1,y1,x2,y2 = line[0]\n",
        "        cv2.line(img,(x1,y1),(x2,y2),(255,0,0),2)\n",
        "    plt.figure(figsize=(20,10))\n",
        "    plt.subplot(121),plt.imshow(img_edge),plt.title('Input',color='c')\n",
        "    plt.subplot(122),plt.imshow(img),plt.title('Output',color='c')\n",
        "    plt.show()\n",
        "    return\n",
        "\n",
        "def houghCircleDetector(path_to_img):\n",
        "    img = cv2.imread(path_to_img)\n",
        "    img = cv2.medianBlur(img,3)\n",
        "    img_edge = cv2.Canny(img,100,200)\n",
        "\n",
        "    circles = cv2.HoughCircles(img_edge,cv2.HOUGH_GRADIENT,1,minDist=20,param1=200,param2=70)\n",
        "    circles = np.uint16(np.around(circles))\n",
        "    for val in circles[0,:]:\n",
        "        cv2.circle(img,(val[0],val[1]),val[2],(255,0,0),2)\n",
        "\n",
        "    plt.figure(figsize=(20,10))\n",
        "    plt.subplot(121),plt.imshow(img_edge),plt.title('Input',color='c')\n",
        "    plt.subplot(122),plt.imshow(img),plt.title('Result',color='c')\n",
        "    plt.show()\n",
        "    return\n",
        "\n",
        "path_to_img = 'sample_imgs/indian_coins.jpg'\n",
        "\n",
        "# houghLineDetector(path_to_img)\n",
        "houghCircleDetector(path_to_img)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "STQrXJwCMhsB",
        "colab_type": "text"
      },
      "source": [
        "### Color Object Detection <a name=\"clr-objdet\"></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UtIXNAecMhsC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#HSV Based\n",
        "def detectColorObjects(path_to_img,find_color=None):\n",
        "    img =cv2.imread(path_to_img)\n",
        "    img_hsv = cv2.cvtColor(img,cv2.COLOR_BGR2HSV)\n",
        "    if find_color == 'red':\n",
        "        Red1Lower = np.array([0,90,100])\n",
        "        Red1Upper = np.array([10,255,255])\n",
        "        #(170-180)\n",
        "        Red2Lower = np.array([170,90,100])\n",
        "        Red2Upper = np.array([180,255,255])\n",
        "        img_mask1 = cv2.inRange(img_hsv,Red1Lower,Red1Upper)\n",
        "        img_mask2 = cv2.inRange(img_hsv,Red2Lower,Red2Upper)\n",
        "        img_mask = img_mask1+img_mask2\n",
        "        masked_out = cv2.bitwise_and(img,img,mask=img_mask)\n",
        "    if find_color == 'green':\n",
        "        GreenLower = np.array([40,100,100])\n",
        "        GreenUpper = np.array([80,255,255])\n",
        "        img_mask = cv2.inRange(img_hsv,GreenLower,GreenUpper)\n",
        "        masked_out = cv2.bitwise_and(img,img,mask=img_mask)\n",
        "    return img,img_mask\n",
        "\n",
        "\n",
        "def markDetectdObjects(og_img,masked_img):\n",
        "    # Find Blue Contours\n",
        "    (contours,_)=cv2.findContours(masked_img,cv2.RETR_TREE,cv2.CHAIN_APPROX_SIMPLE)\n",
        "    FinImg = og_img.copy()\n",
        "    for pic, contour in enumerate(contours):\n",
        "        area = cv2.contourArea(contour)\n",
        "        if(area):\n",
        "            x,y,w,h = cv2.boundingRect(contour)\n",
        "            # FinImg = cv2.rectangle(og_img,(x,y),(x+w,y+h),(0,0,255),2)\n",
        "            cv2.putText(FinImg,\"*\",(int(x+w/2),int(y+h/2)),cv2.FONT_HERSHEY_SIMPLEX,0.7,(255,0,0))\n",
        "            # BaseCord = np.array([x+h+round(w/2), y+h+round(w/2)])\n",
        "    plt.figure(figsize=(10,10))\n",
        "    plt.subplot(131),plt.imshow(cv2.cvtColor(og_img,cv2.COLOR_BGR2RGB)),plt.title('Input',color='c')\n",
        "    plt.subplot(132),plt.imshow(cv2.cvtColor(masked_img,cv2.COLOR_BGR2RGB)),plt.title('Result',color='c')\n",
        "    plt.subplot(133),plt.imshow(cv2.cvtColor(FinImg,cv2.COLOR_BGR2RGB)),plt.title('Result',color='c')\n",
        "    plt.show()\n",
        "    return\n",
        "\n",
        "path_to_img = 'sample_imgs/skittle_rgb.tiff'\n",
        "img,maskedImg =detectColorObjects(path_to_img,find_color='green')\n",
        "markDetectdObjects(img,maskedImg)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NzaGC75AMhsF",
        "colab_type": "text"
      },
      "source": [
        "### Shape object detection <a name=\"shp-objdet\"></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QLRKGP51MhsF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Shape Detection\n",
        "path_to_img = 'sample_imgs/wiki_shapes.jpg'\n",
        "def detectShapes(img_path):\n",
        "    img = cv2.imread(img_path,cv2.IMREAD_GRAYSCALE)\n",
        "    _,img_Otsubin = cv2.threshold(img,127,255,cv2.THRESH_BINARY_INV+cv2.THRESH_OTSU)\n",
        "    contours,_ = cv2.findContours(img_Otsubin.copy(),1,2)\n",
        "    for num,cnt in enumerate(contours):\n",
        "        x,y,w,h = cv2.boundingRect(cnt)\n",
        "        approx = cv2.approxPolyDP(cnt,0.01*cv2.arcLength(cnt,True),True)\n",
        "        # print(num, approx)\n",
        "        if len(approx) == 3:\n",
        "            cv2.putText(img,\"Triangle\",(int(x+w/2),int(y+h/2)),cv2.FONT_HERSHEY_SIMPLEX,1,(0,255,0),2)\n",
        "            cv2.drawContours(img,[cnt],-1,(0,255,0),2)\n",
        "        if len(approx) == 4:\n",
        "            cv2.putText(img,\"Rect\",(int(x+w/2),int(y+h/2)),cv2.FONT_HERSHEY_SIMPLEX,1,(0,255,0),2)\n",
        "            cv2.drawContours(img,[cnt],-1,(0,255,0),2)\n",
        "        if len(approx) > 10:\n",
        "            cv2.putText(img,\"Circle\",(int(x+w/2),int(y+h/2)),cv2.FONT_HERSHEY_SIMPLEX,1,(0,255,0),2)\n",
        "            cv2.drawContours(img,[cnt],-1,(0,255,0),2)\n",
        "            \n",
        "    plt.figure(figsize=(10,10))\n",
        "    plt.subplot(121),plt.imshow(cv2.cvtColor(img_Otsubin,cv2.COLOR_BGR2RGB)),plt.title('Input',color='c')\n",
        "    plt.subplot(122),plt.imshow(cv2.cvtColor(img,cv2.COLOR_BGR2RGB)),plt.title('Result')\n",
        "    plt.show()\n",
        "    return\n",
        "\n",
        "detectShapes(path_to_img)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nSZHXnAFMhsJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Image Segmentation: Watershed Algorithm\n",
        "# Sleep In Progress (^-^)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}